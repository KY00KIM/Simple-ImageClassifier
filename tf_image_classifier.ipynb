{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{"id":"GpSzn36wy1er"},"source":["## 0. Import Dependencies"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":3196,"status":"ok","timestamp":1686418977071,"user":{"displayName":"김창희","userId":"17481081549906567654"},"user_tz":-540},"id":"xDGJpNfzwmuf"},"outputs":[],"source":["import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.applications import Xception\n","from tensorflow.keras.layers import Flatten, Dense, Dropout, GlobalAveragePooling2D\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.layers import Dense, Input, Activation, Flatten\n","import os\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from tensorflow.keras.layers import Dense, Input, Activation, Flatten\n","from tensorflow.keras.layers import BatchNormalization,Add,Dropout\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.models import Model, load_model\n","from tensorflow.keras.layers import LeakyReLU, ReLU, Conv2D, MaxPooling2D, BatchNormalization, Conv2DTranspose, UpSampling2D, concatenate\n","from tensorflow.keras import callbacks\n","from tensorflow.keras import backend as K\n","from tensorflow.keras.applications import ResNet50\n","from tensorflow.python.keras.callbacks import EarlyStopping, ModelCheckpoint\n","from keras.utils import load_img, img_to_array\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"airF_mGu1djN"},"source":["## 1. Model initialization"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4208,"status":"ok","timestamp":1686418983921,"user":{"displayName":"김창희","userId":"17481081549906567654"},"user_tz":-540},"id":"UDrOQzsj0crF","outputId":"ed7cf5f9-19e1-4402-f02b-0e06b06c3ec1"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"KyuminRes50\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," resnet50 (Functional)       (None, 2048)              23587712  \n","                                                                 \n"," flatten (Flatten)           (None, 2048)              0         \n","                                                                 \n"," dense (Dense)               (None, 1024)              2098176   \n","                                                                 \n"," dense_1 (Dense)             (None, 3)                 3075      \n","                                                                 \n","=================================================================\n","Total params: 25,688,963\n","Trainable params: 2,101,251\n","Non-trainable params: 23,587,712\n","_________________________________________________________________\n"]}],"source":["# Image Size\n","IMAGE_SIZE = (500,500)\n","MODEL_NAME = \"KyuminRes50\"\n","\n","model = Sequential(name=MODEL_NAME)\n","\n","model.add(ResNet50(include_top = False, pooling = 'max', input_shape=(IMAGE_SIZE[0], IMAGE_SIZE[1], 3), weights = 'imagenet', classes=3))\n","model.add(Flatten())\n","model.add(Dense(1024, activation = 'relu'))\n","\n","model.add(Dense(3, activation = 'softmax'))\n","\n","# DO NOT train pretrained model : ResNet50\n","model.layers[0].trainable = False\n","model.summary()"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"TImkIPFV5oKl"},"source":["## 2. Model Compilation"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1686418983921,"user":{"displayName":"김창희","userId":"17481081549906567654"},"user_tz":-540},"id":"E6PDUyLn0dSc"},"outputs":[],"source":["model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"DaCn_zpB6STq"},"source":["## 3. Train/Validation Data Preparation"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1686418983921,"user":{"displayName":"김창희","userId":"17481081549906567654"},"user_tz":-540},"id":"6WmZ6fL30ee4","outputId":"fbc33d30-243d-4405-e9bb-f4e4ef924f0a"},"outputs":[{"name":"stdout","output_type":"stream","text":["Found 5507 images belonging to 3 classes.\n","Found 1089 images belonging to 3 classes.\n","data label:  {'0.NOFINDING': 0, '1.THORAXDISEASE': 1, '2.COVID-19': 2}\n","data label:  {'0.NOFINDING': 0, '1.THORAXDISEASE': 1, '2.COVID-19': 2}\n"]}],"source":["train_dir = '/path/to/TRAIN_DATA/'\n","valid_dir = '/path/to/VALIDATION_DATA/'\n","# Batch Size\n","BATCH_SIZE = 128\n","\n","# Augmentation for training data\n","data_gen = ImageDataGenerator(\n","                              rotation_range=10,\n","                              width_shift_range=0.1,\n","                              height_shift_range=0.1,\n","                              shear_range=0.1,\n","                              zoom_range=0.1)\n","\n","train_gen = data_gen.flow_from_directory(\n","                                                train_dir, \n","                                                batch_size=BATCH_SIZE,\n","                                                color_mode='rgb',\n","                                                shuffle=True,\n","                                                class_mode='categorical',\n","                                                target_size=IMAGE_SIZE)\n","\n","# No-Augmentation for validation data\n","default_gen = ImageDataGenerator()\n","valid_gen = default_gen.flow_from_directory(\n","                                                valid_dir,\n","                                                target_size=IMAGE_SIZE,\n","                                                batch_size=BATCH_SIZE,\n","                                                class_mode='categorical') \n","\n","print(\"training data label: \", train_gen.class_indices)\n","print(\"validation data label: \", valid_gen.class_indices)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## 3-1. Visualize Augmented Images"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gz3UgrxjrAuG"},"outputs":[],"source":["###### Reinitialization required for DirectoryItrator after iteration #######\n","\n","MY_DIRECTORY_ITERATOR = None # e.g. ImageDataGenerator().flow_from_directory()\n","\n","plt.figure(figsize=(10, 10))\n","for i in range(9):\n","    ax = plt.subplot(3, 3, i + 1)\n","    image, label = next(SOME_DIRECTORY_ITERATOR)\n","    image = image.astype('uint8')\n","    image =  image.reshape(image.shape[1], image.shape[2], image.shape[3])\n","    plt.imshow(image)\n","    plt.axis(\"off\")"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"mXf29zCB_NvL"},"source":["## 4. Checkpoint config"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":470,"status":"ok","timestamp":1686418993942,"user":{"displayName":"김창희","userId":"17481081549906567654"},"user_tz":-540},"id":"weUshcUs0fMR"},"outputs":[],"source":["cb_early_stopper = EarlyStopping(monitor = 'val_loss', patience = 3)\n","cb_checkpointer = ModelCheckpoint(filepath = f'/path/to/save_model/my_model.hdf5', monitor = 'val_loss', save_best_only = True, mode = 'auto')"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"GhEvjvNb_QrM"},"source":["## 5. Model Train"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CsgREQVu0fSL","outputId":"0dbd50a7-3ed7-4f12-ba49-4e73e57c18b8"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/60\n","44/44 [==============================] - 3648s 83s/step - loss: 12.5991 - accuracy: 0.6691 - val_loss: 1.1053 - val_accuracy: 0.7034\n","Epoch 2/60\n","10/44 [=====>........................] - ETA: 4:54 - loss: 0.3992 - accuracy: 0.8781"]}],"source":["fit_history = model.fit(\n","        train_gen,\n","        epochs = 60,\n","        validation_data=valid_gen,\n","        callbacks=[cb_checkpointer, cb_early_stopper]\n",")"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"InofBvofXRrw"},"source":["## 5-1. Notification on train completion\n","\n","- notification sent on training completion, via [ntfy.sh](https://ntfy.sh/)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"S5x7K5vUWlzi"},"outputs":[],"source":["import requests\n","requests.post(\"https://ntfy.sh/MY_NOTI_CHANNEL\",\n","    data=f\"Training on {MODEL_NAME} is Done!\",\n","    headers={\n","        \"Title\": \"Training Done!\",\n","        \"Priority\": \"urgent\",\n","        \"Tags\": \"warning\"\n","    })"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"VR8SyfDCXY1V"},"source":["## 6. Show training result"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OPtBx5tN0fWQ"},"outputs":[],"source":["print(\"fit history keys : \",fit_history.history.keys())\n","plt.figure(1, figsize=(15,8))\n","\n","plt.subplot(221)\n","plt.plot(fit_history.history['accuracy'])\n","plt.plot(fit_history.history['val_accuracy'])\n","plt.title('model_accuracy')\n","plt.ylabel('accuracy')\n","plt.xlabel('epoch')\n","plt.legend(['train', 'valid'])\n","\n","plt.subplot(222)\n","plt.plot(fit_history.history['loss'])\n","plt.plot(fit_history.history['val_loss'])\n","plt.title('model_loss')\n","plt.ylabel('loss')\n","plt.xlabel('epoch')\n","plt.legend(['train', 'valid'])\n","\n","plt.show()"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"7TGo02MnXdUi"},"source":["## 7. Prediction on data directory"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PZHv36rw0faK"},"outputs":[],"source":["test_dir = '/path/to/test_data/'\n","model_path = '/path/to/my_model.hdf5'\n","\n","model = load_model(model_path)\n","imgs = [file for file in os.listdir(test_dir)]\n","with open ('/path/to/result_text.txt', 'w') as f:\n","  for image_name in imgs:\n","    full_img_path = os.path.join(test_dir, image_name)\n","    image = load_img(full_img_path, target_size=IMAGE_SIZE)\n","    image = img_to_array(image)\n","    image = np.expand_dims(image, axis=0)\n","\n","    predictions = model.predict(image, verbose=0)\n","    predicted_class = np.argmax(predictions, axis=1)[0]\n","    class_name = ['NOFINDING', 'THORAXDISEASE', 'COVID-19']\n","    \n","    print(f\"{image_name}\\t{predicted_class}\\t{class_name[predicted_class]}\")\n","    f.write(f\"{image_name}\\t{predicted_class}\\t{class_name[predicted_class]}\")"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyOGVDGuhaQsuRwZ2rK6Dgdh","collapsed_sections":["jC5mQBVmyx0T","BfWx3LAmzIwV","MpDOEwSt4Hze"],"gpuType":"T4","mount_file_id":"1_ItbfJL5JoH_wKrLYaBSXNovX3Zay6uv","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
